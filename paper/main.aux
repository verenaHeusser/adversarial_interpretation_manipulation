\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{ruede2020multi,brinker2019deep,nguyen2020super}
\citation{adadi2018peeking}
\citation{chouldechova2017fair,elshawi2019interpretability,whitmore2016mapping}
\@writefile{toc}{\contentsline {section}{Abstract}{1}{section*.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\newlabel{sec:introduction}{{1}{1}{Introduction}{section.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Prediction pipeline using a machine learning model, depicted as blach box. Typically, evaluation metrics require the prediction $y$ and the ground truth label $y^*$ allowing for the assessmant of the model's accuracy. Additionally answering the question \textit  {why}, i.e. making the model interpretable for a human, requires additional methods.\relax }}{1}{figure.caption.2}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:bb}{{1}{1}{Prediction pipeline using a machine learning model, depicted as blach box. Typically, evaluation metrics require the prediction $y$ and the ground truth label $y^*$ allowing for the assessmant of the model's accuracy. Additionally answering the question \textit {why}, i.e. making the model interpretable for a human, requires additional methods.\relax }{figure.caption.2}{}}
\citation{bach2015pixel}
\citation{szegedy2016rethinking}
\citation{ILSVRC15}
\citation{bach2015pixel,simonyan2013deep,zeiler2014visualizing}
\citation{ancona2017towards,arras2017relevant}
\citation{evaluating_explanations_security}
\citation{murdoch2019definitions,lipton2018mythos}
\citation{lipton2018mythos}
\citation{lipton2018mythos}
\citation{arrieta2020explainable}
\newlabel{fig:lrp_cat_orig}{{2a}{2}{Original.\relax }{figure.caption.3}{}}
\newlabel{sub@fig:lrp_cat_orig}{{a}{2}{Original.\relax }{figure.caption.3}{}}
\newlabel{fig:lrp_cat_lrp}{{2b}{2}{Feature importance map.\relax }{figure.caption.3}{}}
\newlabel{sub@fig:lrp_cat_lrp}{{b}{2}{Feature importance map.\relax }{figure.caption.3}{}}
\newlabel{fig:cat_classification}{{2c}{2}{Predictive accuracy.\relax }{figure.caption.3}{}}
\newlabel{sub@fig:cat_classification}{{c}{2}{Predictive accuracy.\relax }{figure.caption.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Visualization of the feature importance map produced py the LRP interpreter applied to the image of a cat and an image classification model.\relax }}{2}{figure.caption.3}\protected@file@percent }
\newlabel{fig:lrp_cat}{{2}{2}{Visualization of the feature importance map produced py the LRP interpreter applied to the image of a cat and an image classification model.\relax }{figure.caption.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Interpretation Methods}{2}{section.2}\protected@file@percent }
\newlabel{sec:interpretation_methods}{{2}{2}{Interpretation Methods}{section.2}{}}
\citation{arrieta2020explainable}
\citation{lipton2018mythos}
\citation{arrieta2020explainable}
\citation{arrieta2020explainable}
\citation{xiao2020noise}
\citation{kim2018interpretability,nguyen2017plug,yosinski2015understanding}
\citation{ribeiro2016should,lundberg2017unified,bach2015pixel}
\citation{evaluating_explanations_security}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Why is Interpretability Important?}{3}{subsection.2.1}\protected@file@percent }
\newlabel{subsec:importance_of_interpretability}{{2.1}{3}{Why is Interpretability Important?}{subsection.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Terminology}{3}{subsection.2.2}\protected@file@percent }
\newlabel{subsec:interpretation_methods_terminology}{{2.2}{3}{Terminology}{subsection.2.2}{}}
\citation{elshawi2019interpretability,whitmore2016mapping}
\citation{ribeiro2016should}
\citation{szegedy2016rethinking}
\citation{ILSVRC15}
\citation{lundberg2017unified}
\citation{bach2015pixel}
\citation{bach2015pixel}
\citation{selvaraju2017grad}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Model-agnostic methods.}{4}{subsection.2.3}\protected@file@percent }
\newlabel{subsec:bb_methods}{{2.3}{4}{Model-agnostic methods}{subsection.2.3}{}}
\newlabel{fig:bird-a}{{3a}{4}{Original\relax }{figure.caption.4}{}}
\newlabel{sub@fig:bird-a}{{a}{4}{Original\relax }{figure.caption.4}{}}
\newlabel{fig:bird-a}{{3b}{4}{Mask.\relax }{figure.caption.4}{}}
\newlabel{sub@fig:bird-a}{{b}{4}{Mask.\relax }{figure.caption.4}{}}
\newlabel{fig:bird-a}{{3c}{4}{Saliency Map.\relax }{figure.caption.4}{}}
\newlabel{sub@fig:bird-a}{{c}{4}{Saliency Map.\relax }{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Visualization of the output of the LIME interpreter applied to an image and image classification model.\relax }}{4}{figure.caption.4}\protected@file@percent }
\newlabel{fig:lime_cat}{{3}{4}{Visualization of the output of the LIME interpreter applied to an image and image classification model.\relax }{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Visualization of the output of the SHAP interpreter applied to applied to an image and image classification model.\relax }}{4}{figure.caption.5}\protected@file@percent }
\newlabel{fig:shap_dog}{{4}{4}{Visualization of the output of the SHAP interpreter applied to applied to an image and image classification model.\relax }{figure.caption.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Model-transparent methods.}{4}{subsection.2.4}\protected@file@percent }
\newlabel{subsec:wb_methods}{{2.4}{4}{Model-transparent methods}{subsection.2.4}{}}
\citation{gao2019universal,kereliuk2015deep}
\citation{szegedy_intriguing}
\citation{adebayo2018sanity,samek2019explainable,alvarez2018towards}
\citation{dombrowski2019explanations}
\citation{dimanov2020you}
\citation{fooling_nn_interpreters}
\citation{fooling_nn_interpreters}
\@writefile{toc}{\contentsline {section}{\numberline {3}Manipulation Methods}{5}{section.3}\protected@file@percent }
\newlabel{sec:manipulation_methods}{{3}{5}{Manipulation Methods}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Adversarial Setting}{5}{subsection.3.1}\protected@file@percent }
\newlabel{subsec:adversarial_setting}{{3.1}{5}{Adversarial Setting}{subsection.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Taxonomy of Manipulation Methods}{5}{subsection.3.2}\protected@file@percent }
\newlabel{subsec:taxonomy_manipulations}{{3.2}{5}{Taxonomy of Manipulation Methods}{subsection.3.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}Manipulation Levels}{5}{subsubsection.3.2.1}\protected@file@percent }
\newlabel{subsubsec:manipulation_levels}{{3.2.1}{5}{Manipulation Levels}{subsubsection.3.2.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Depiction of an adversarial input manipulation. The model is fine-tuned with altered input samples, which are indicated by $\mathbf  {x}+\delta $.\relax }}{5}{figure.caption.6}\protected@file@percent }
\newlabel{fig:input_manipulation}{{5}{5}{Depiction of an adversarial input manipulation. The model is fine-tuned with altered input samples, which are indicated by $\mathbf {x}+\delta $.\relax }{figure.caption.6}{}}
\citation{fooling_nn_interpreters}
\citation{ghorbani2019interpretation}
\citation{spearman1961proof}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Depiction of an adversarial model manipulation. The model is fine-tuned with the same distribution of input data and a fooling loss, thus yielding the biased model $N+\delta $.\relax }}{6}{figure.caption.7}\protected@file@percent }
\newlabel{fig:input_manipulation}{{6}{6}{Depiction of an adversarial model manipulation. The model is fine-tuned with the same distribution of input data and a fooling loss, thus yielding the biased model $N+\delta $.\relax }{figure.caption.7}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2}Manipulation Targets}{6}{subsubsection.3.2.2}\protected@file@percent }
\newlabel{subsubsec:manipulation_targets}{{3.2.2}{6}{Manipulation Targets}{subsubsection.3.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Evaluation Criteria}{6}{subsection.3.3}\protected@file@percent }
\newlabel{subsec:eval_criteria_manipulations}{{3.3}{6}{Evaluation Criteria}{subsection.3.3}{}}
\citation{fooling_nn_interpreters}
\citation{adebayo2018sanity}
\citation{advlime_aies20}
\citation{fooling_nn_interpreters}
\citation{dimanov2020you}
\citation{fooling_nn_interpreters}
\citation{fooling_nn_interpreters}
\citation{dimanov2020you}
\citation{adebayo2018sanity}
\citation{fooling_nn_interpreters}
\@writefile{toc}{\contentsline {section}{\numberline {4}Interpreter Manipulation Method Examples}{7}{section.4}\protected@file@percent }
\newlabel{sec:manipulations}{{4}{7}{Interpreter Manipulation Method Examples}{section.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Input Level Manipulations}{7}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Model Level Manipulations}{7}{subsection.4.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Principal Component Analysis (PCA) on the original data (orange) of the COMPAS dataset and the samples perturbed by LIME (blue). Note that the differences are obvious even in the space reduced to two dimensions.\relax }}{7}{figure.caption.8}\protected@file@percent }
\newlabel{fig:slack_ood_data}{{7}{7}{Principal Component Analysis (PCA) on the original data (orange) of the COMPAS dataset and the samples perturbed by LIME (blue). Note that the differences are obvious even in the space reduced to two dimensions.\relax }{figure.caption.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Explaining Manipulations}{7}{section.5}\protected@file@percent }
\newlabel{sec:explaining_manipulations}{{5}{7}{Explaining Manipulations}{section.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Uncovering Manipulations}{7}{section.6}\protected@file@percent }
\newlabel{sec:uncovering_manipulations}{{6}{7}{Uncovering Manipulations}{section.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Sanity Checks for Interpreters}{7}{section.7}\protected@file@percent }
\newlabel{sec:sanity_checks_for_interpreters}{{7}{7}{Sanity Checks for Interpreters}{section.7}{}}
\citation{lipton2018mythos}
\bibdata{mybib}
\bibstyle{ACM-Reference-Format}
\newlabel{tocindent-1}{0pt}
\newlabel{tocindent0}{0pt}
\newlabel{tocindent1}{0pt}
\newlabel{tocindent2}{0pt}
\newlabel{tocindent3}{0pt}
\@writefile{toc}{\contentsline {section}{\numberline {8}Benchmarking Interpretations}{8}{section.8}\protected@file@percent }
\newlabel{sec:benchmarking}{{8}{8}{Benchmarking Interpretations}{section.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {9}Discussion}{8}{section.9}\protected@file@percent }
\newlabel{sec:discussion}{{9}{8}{Discussion}{section.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.1}Conclusion}{8}{subsection.9.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.2}Future Work}{8}{subsection.9.2}\protected@file@percent }
\newlabel{TotPages}{{8}{8}{}{page.8}{}}
