\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{ruede2020multi,brinker2019deep,nguyen2020super}
\citation{chouldechova2017fair,elshawi2019interpretability,whitmore2016mapping}
\citation{adadi2018peeking}
\@writefile{toc}{\contentsline {section}{Abstract}{1}{section*.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\newlabel{sec:introduction}{{1}{1}{Introduction}{section.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Prediction pipeline using a machine learning model, depicted as \DIFdelbeginFL  {\color {red}\sout {a }}\DIFdelendFL  black box. Typically, evaluation metrics require the prediction $y$ and the ground truth label $y^*$ allowing for the \DIFdelbeginFL  {\color {red}\sout {assessmant }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {assessment }}\DIFaddendFL  of the model's accuracy. Additionally answering the question \textit  {why}, i.e. making the model interpretable for a human, requires additional methods.\relax }}{1}{figure.caption.2}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:bb}{{1}{1}{Prediction pipeline using a machine learning model, depicted as \DIFdelbeginFL \DIFdelFL {a }\DIFdelendFL black box. Typically, evaluation metrics require the prediction $y$ and the ground truth label $y^*$ allowing for the \DIFdelbeginFL \DIFdelFL {assessmant }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {assessment }\DIFaddendFL of the model's accuracy. Additionally answering the question \textit {why}, i.e. making the model interpretable for a human, requires additional methods.\relax }{figure.caption.2}{}}
\citation{bach2015pixel}
\citation{szegedy2016rethinking}
\citation{ILSVRC15}
\citation{fooling_nn_interpreters}
\citation{fooling_nn_interpreters}
\citation{bach2015pixel,simonyan2013deep,zeiler2014visualizing}
\citation{ancona2017towards,arras2017relevant}
\citation{evaluating_explanations_security}
\citation{hase2020evaluating}
\citation{poursabzi2018manipulating}
\citation{kaur2020interpreting}
\citation{murdoch2019definitions,lipton2018mythos}
\citation{fooling_nn_interpreters,ghorbani2019interpretation,dimanov2020you,dombrowski2019explanations,advlime_aies20,le2020remote,zhang2020interpretable,kuppa2020black,anders2020fairwashing,lakkaraju2020fool,kindermans2017reliability}
\citation{lipton2018mythos}
\citation{lipton2018mythos}
\citation{arrieta2020explainable}
\citation{arrieta2020explainable}
\citation{lipton2018mythos}
\citation{arrieta2020explainable}
\citation{arrieta2020explainable}
\citation{xiao2020noise}
\newlabel{fig:lrp_cat_orig}{{2a}{2}{Original.\relax }{figure.caption.3}{}}
\newlabel{sub@fig:lrp_cat_orig}{{a}{2}{Original.\relax }{figure.caption.3}{}}
\newlabel{fig:lrp_cat_lrp}{{2b}{2}{Map.\relax }{figure.caption.3}{}}
\newlabel{sub@fig:lrp_cat_lrp}{{b}{2}{Map.\relax }{figure.caption.3}{}}
\newlabel{fig:lrp_cat_fooled_lrp}{{2c}{2}{Fooled Map.\relax }{figure.caption.3}{}}
\newlabel{sub@fig:lrp_cat_fooled_lrp}{{c}{2}{Fooled Map.\relax }{figure.caption.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Visualization of the feature importance and fooled feature importance maps produced py the LRP interpreter applied to the image of a cat and an image classification model. The fooling method is the \textit  {location} fooling from \citep  {fooling_nn_interpreters}. Dark red here means a stronger significance of the feature.\relax }}{2}{figure.caption.3}\protected@file@percent }
\newlabel{fig:lrp_cat}{{2}{2}{Visualization of the feature importance and fooled feature importance maps produced py the LRP interpreter applied to the image of a cat and an image classification model. The fooling method is the \textit {location} fooling from \cite {fooling_nn_interpreters}. Dark red here means a stronger significance of the feature.\relax }{figure.caption.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Interpretation Methods}{2}{section.2}\protected@file@percent }
\newlabel{sec:interpretation_methods}{{2}{2}{Interpretation Methods}{section.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Terminology}{2}{subsection.2.1}\protected@file@percent }
\newlabel{subsec:interpretation_methods_terminology}{{2.1}{2}{Terminology}{subsection.2.1}{}}
\citation{kim2018interpretability,nguyen2017plug,yosinski2015understanding}
\citation{ribeiro2016should,lundberg2017unified,bach2015pixel}
\citation{evaluating_explanations_security}
\citation{elshawi2019interpretability,whitmore2016mapping}
\citation{ribeiro2016should}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Model-agnostic methods.}{3}{subsection.2.2}\protected@file@percent }
\newlabel{subsec:bb_methods}{{2.2}{3}{Model-agnostic methods}{subsection.2.2}{}}
\citation{szegedy2016rethinking}
\citation{ILSVRC15}
\citation{lundberg2017unified}
\citation{bach2015pixel}
\citation{shrikumar2017learning}
\citation{smilkov2017smoothgrad}
\citation{selvaraju2017grad}
\citation{simonyan2013deep}
\citation{gao2019universal,kereliuk2015deep}
\citation{szegedy_intriguing}
\newlabel{fig:bird-a}{{3a}{4}{Original\relax }{figure.caption.4}{}}
\newlabel{sub@fig:bird-a}{{a}{4}{Original\relax }{figure.caption.4}{}}
\newlabel{fig:bird-a}{{3b}{4}{Mask.\relax }{figure.caption.4}{}}
\newlabel{sub@fig:bird-a}{{b}{4}{Mask.\relax }{figure.caption.4}{}}
\newlabel{fig:bird-a}{{3c}{4}{Saliency Map.\relax }{figure.caption.4}{}}
\newlabel{sub@fig:bird-a}{{c}{4}{Saliency Map.\relax }{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Visualization of the output of the LIME interpreter applied to an image and image classification model.\relax }}{4}{figure.caption.4}\protected@file@percent }
\newlabel{fig:lime_cat}{{3}{4}{Visualization of the output of the LIME interpreter applied to an image and image classification model.\relax }{figure.caption.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Visualization of the output of the SHAP interpreter applied to applied to an image and image classification model.\relax }}{4}{figure.caption.5}\protected@file@percent }
\newlabel{fig:shap_dog}{{4}{4}{Visualization of the output of the SHAP interpreter applied to applied to an image and image classification model.\relax }{figure.caption.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Model-transparent methods.}{4}{subsection.2.3}\protected@file@percent }
\newlabel{subsec:wb_methods}{{2.3}{4}{Model-transparent methods}{subsection.2.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Manipulation Methods}{4}{section.3}\protected@file@percent }
\newlabel{sec:manipulation_methods}{{3}{4}{Manipulation Methods}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Adversarial Setting}{4}{subsection.3.1}\protected@file@percent }
\newlabel{subsec:adversarial_setting}{{3.1}{4}{Adversarial Setting}{subsection.3.1}{}}
\citation{adebayo2018sanity,samek2019explainable,alvarez2018towards}
\citation{fooling_nn_interpreters,dimanov2020you}
\citation{dombrowski2019explanations}
\citation{fooling_nn_interpreters}
\citation{dimanov2020you}
\citation{dombrowski2019explanations}
\citation{fooling_nn_interpreters}
\citation{fooling_nn_interpreters}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Taxonomy of Interpretation Manipulation Methods}{5}{subsection.3.2}\protected@file@percent }
\newlabel{subsec:taxonomy_manipulations}{{3.2}{5}{Taxonomy of Interpretation Manipulation Methods}{subsection.3.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.1}Manipulation Levels}{5}{subsubsection.3.2.1}\protected@file@percent }
\newlabel{subsubsec:manipulation_levels}{{3.2.1}{5}{Manipulation Levels}{subsubsection.3.2.1}{}}
\citation{fooling_nn_interpreters}
\citation{simonyan2013deep}
\citation{fooling_nn_interpreters}
\citation{adebayo2018sanity}
\citation{ghorbani2019interpretation}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Depiction of an adversarial input manipulation. The model is fine-tuned with altered input samples, which are indicated by $\mathbf  {x}+\delta $.\relax }}{6}{figure.caption.6}\protected@file@percent }
\newlabel{fig:input_manipulation}{{5}{6}{Depiction of an adversarial input manipulation. The model is fine-tuned with altered input samples, which are indicated by $\mathbf {x}+\delta $.\relax }{figure.caption.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Depiction of an adversarial model manipulation. The model is fine-tuned with the same distribution of input data and a fooling loss, thus yielding the biased model $N+\delta $.\relax }}{6}{figure.caption.7}\protected@file@percent }
\newlabel{fig:input_manipulation}{{6}{6}{Depiction of an adversarial model manipulation. The model is fine-tuned with the same distribution of input data and a fooling loss, thus yielding the biased model $N+\delta $.\relax }{figure.caption.7}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.2.2}Manipulation Targets}{6}{subsubsection.3.2.2}\protected@file@percent }
\newlabel{subsubsec:manipulation_targets}{{3.2.2}{6}{Manipulation Targets}{subsubsection.3.2.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Evaluation Criteria}{6}{subsection.3.3}\protected@file@percent }
\newlabel{subsec:eval_criteria_manipulations}{{3.3}{6}{Evaluation Criteria}{subsection.3.3}{}}
\citation{fooling_nn_interpreters}
\citation{samek2016evaluating}
\citation{fooling_nn_interpreters}
\citation{ghorbani2019interpretation}
\citation{spearman1961proof}
\citation{adebayo2018sanity}
\citation{adebayo2018sanity}
\citation{subramanya2019fooling}
\citation{subramanya2019fooling}
\citation{subramanya2019fooling}
\citation{dombrowski2019explanations}
\citation{dombrowski2019explanations}
\citation{dombrowski2019explanations}
\citation{ghorbani2019interpretation}
\citation{dombrowski2019explanations}
\@writefile{toc}{\contentsline {section}{\numberline {4}Interpreter Manipulation Method Examples}{7}{section.4}\protected@file@percent }
\newlabel{sec:manipulations}{{4}{7}{Interpreter Manipulation Method Examples}{section.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Input Level Manipulations}{7}{subsection.4.1}\protected@file@percent }
\newlabel{fig:patch_original}{{7a}{7}{\scriptsize {Original. \newline Pred: 'French bulldog'.}\relax }{figure.caption.8}{}}
\newlabel{sub@fig:patch_original}{{a}{7}{\scriptsize {Original. \newline Pred: 'French bulldog'.}\relax }{figure.caption.8}{}}
\newlabel{fig:patch_plus_dog}{{7b}{7}{\scriptsize {Original with\newline Patch.}\relax }{figure.caption.8}{}}
\newlabel{sub@fig:patch_plus_dog}{{b}{7}{\scriptsize {Original with\newline Patch.}\relax }{figure.caption.8}{}}
\newlabel{fig:patch_fooled}{{7c}{7}{\scriptsize {Fooled Map, fooled \newline model. Pred: 'Soccer ball'.}\relax }{figure.caption.8}{}}
\newlabel{sub@fig:patch_fooled}{{c}{7}{\scriptsize {Fooled Map, fooled \newline model. Pred: 'Soccer ball'.}\relax }{figure.caption.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Fooling of the model and GradCAM. The interpreter is \DIFdelbeginFL  {\color {red}\sout {fooled is }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {deceived as }}\DIFaddendFL  it takes the \DIFaddbeginFL  {\color {blue}\uwave {features of the }}\DIFaddendFL  original target \DIFdelbeginFL  {\color {red}\sout {classe's features }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {class }}\DIFaddendFL  as evidence \DIFdelbeginFL  {\color {red}\sout {for }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {of }}\DIFaddendFL  the wrong class. Images from \citep  {subramanya2019fooling}.\relax }}{7}{figure.caption.8}\protected@file@percent }
\newlabel{fig:patch_fooling}{{7}{7}{Fooling of the model and GradCAM. The interpreter is \DIFdelbeginFL \DIFdelFL {fooled is }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {deceived as }\DIFaddendFL it takes the \DIFaddbeginFL \DIFaddFL {features of the }\DIFaddendFL original target \DIFdelbeginFL \DIFdelFL {classe's features }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {class }\DIFaddendFL as evidence \DIFdelbeginFL \DIFdelFL {for }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {of }\DIFaddendFL the wrong class. Images from \cite {subramanya2019fooling}.\relax }{figure.caption.8}{}}
\citation{fooling_nn_interpreters}
\citation{fooling_nn_interpreters}
\citation{fooling_nn_interpreters}
\citation{advlime_aies20}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces On the left, the original image with corresponding interpretation map is shown. The right column shows the imperceptibly perturbed input image and it's explanation. The target interpretation map was chosen to be an image with the text "this explanation was manipulated". Image from \citep  {dombrowski2019explanations}.\relax }}{8}{figure.caption.9}\protected@file@percent }
\newlabel{fig:dombr}{{8}{8}{On the left, the original image with corresponding interpretation map is shown. The right column shows the imperceptibly perturbed input image and it's explanation. The target interpretation map was chosen to be an image with the text "this explanation was manipulated". Image from \cite {dombrowski2019explanations}.\relax }{figure.caption.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Model Level Manipulations}{8}{subsection.4.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Fooling of LRP and GradCAM. Passive fooling causes the interpreters to highlight wrong, uninformative pixels. Active shifts the interpreters indications from a correct \DIFdelbeginFL  {\color {red}\sout {class }}\DIFdelendFL  (\textit  {elephant}) to a wrong \DIFdelbeginFL  {\color {red}\sout {calss }}\DIFdelendFL  \DIFaddbeginFL  {\color {blue}\uwave {class }}\DIFaddendFL  \textit  {(fire truck}). \DIFaddbeginFL  {\color {blue}\uwave {Image from \mbox  {\citep  {fooling_nn_interpreters}}\hspace  {0pt}.}}\DIFaddendFL  \relax }}{8}{figure.caption.10}\protected@file@percent }
\newlabel{fig:heo_intro}{{9}{8}{Fooling of LRP and GradCAM. Passive fooling causes the interpreters to highlight wrong, uninformative pixels. Active shifts the interpreters indications from a correct \DIFdelbeginFL \DIFdelFL {class }\DIFdelendFL (\textit {elephant}) to a wrong \DIFdelbeginFL \DIFdelFL {calss }\DIFdelendFL \DIFaddbeginFL \DIFaddFL {class }\DIFaddendFL \textit {(fire truck}). \DIFaddbeginFL \DIFaddFL {Image from \mbox {\cite {fooling_nn_interpreters}}\hspace {0pt}.}\DIFaddendFL \relax }{figure.caption.10}{}}
\citation{dimanov2020you}
\citation{fooling_nn_interpreters}
\citation{fooling_nn_interpreters}
\citation{dimanov2020you}
\citation{adebayo2018sanity}
\citation{compas_dataset}
\citation{adult_income}
\citation{fooling_nn_interpreters}
\citation{subramanya2019fooling}
\citation{dimanov2020you,advlime_aies20}
\citation{fooling_nn_interpreters}
\citation{dombrowski2019explanations}
\citation{jain2019attention}
\citation{lipton2018mythos}
\bibdata{mybib}
\bibstyle{ACM-Reference-Format}
\newlabel{tocindent-1}{0pt}
\newlabel{tocindent0}{0pt}
\newlabel{tocindent1}{0pt}
\newlabel{tocindent2}{0pt}
\newlabel{tocindent3}{0pt}
\@writefile{toc}{\contentsline {section}{\numberline {5}Benchmarking Interpretations}{9}{section.5}\protected@file@percent }
\newlabel{sec:benchmarking}{{5}{9}{Benchmarking Interpretations}{section.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusion}{9}{section.6}\protected@file@percent }
\newlabel{sec:discussion}{{6}{9}{Conclusion}{section.6}{}}
\newlabel{TotPages}{{9}{9}{}{page.9}{}}
\gdef \@abspage@last{9}
